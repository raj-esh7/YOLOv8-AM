{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9262257,"sourceType":"datasetVersion","datasetId":5604462}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-30T09:08:31.453361Z","iopub.execute_input":"2024-08-30T09:08:31.453687Z","iopub.status.idle":"2024-08-30T09:08:33.590832Z","shell.execute_reply.started":"2024-08-30T09:08:31.453652Z","shell.execute_reply":"2024-08-30T09:08:33.589568Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Installing dependecies","metadata":{}},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"execution":{"iopub.status.busy":"2024-08-30T09:08:33.593115Z","iopub.execute_input":"2024-08-30T09:08:33.593691Z","iopub.status.idle":"2024-08-30T09:08:48.938632Z","shell.execute_reply.started":"2024-08-30T09:08:33.593643Z","shell.execute_reply":"2024-08-30T09:08:48.937447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U ipywidgets","metadata":{"execution":{"iopub.status.busy":"2024-08-30T09:08:48.940025Z","iopub.execute_input":"2024-08-30T09:08:48.940352Z","iopub.status.idle":"2024-08-30T09:09:03.009182Z","shell.execute_reply.started":"2024-08-30T09:08:48.940317Z","shell.execute_reply":"2024-08-30T09:09:03.008077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install wandb","metadata":{"execution":{"iopub.status.busy":"2024-08-30T09:09:03.012354Z","iopub.execute_input":"2024-08-30T09:09:03.013055Z","iopub.status.idle":"2024-08-30T09:09:15.797377Z","shell.execute_reply.started":"2024-08-30T09:09:03.013006Z","shell.execute_reply":"2024-08-30T09:09:15.796167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Importing libraries","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport os\nimport shutil\nimport xml.etree.ElementTree as ET\nimport cv2\nimport matplotlib.pyplot as plt\nimport torch\nfrom ultralytics import YOLO\nimport wandb","metadata":{"execution":{"iopub.status.busy":"2024-08-30T09:09:15.799092Z","iopub.execute_input":"2024-08-30T09:09:15.799396Z","iopub.status.idle":"2024-08-30T09:09:20.689025Z","shell.execute_reply.started":"2024-08-30T09:09:15.799364Z","shell.execute_reply":"2024-08-30T09:09:20.688228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define base paths\nbase_dataset_path = '/kaggle/input/idd-dataset/IDD_Detection_Organized'\noutput_base_path = '/kaggle/working/IDD_Detection_YOLO'\nsubsets = ['train', 'val']\n\n# Define the classes and their indices\nclasses = {\n    'person': 0,\n    'rider': 1,\n    'motorcycle': 2,\n    'bicycle': 3,\n    'autorickshaw': 4,\n    'car': 5,\n    'truck': 6,\n    'bus': 7,\n    'traffic light': 8,\n    'traffic sign': 9\n}\n\n# Classes to ignore during label update\nclasses_to_ignore = {'traffic sign', 'bicycle', 'traffic light'}\nindices_to_ignore = {classes[class_name] for class_name in classes_to_ignore}","metadata":{"execution":{"iopub.status.busy":"2024-08-30T09:09:20.690166Z","iopub.execute_input":"2024-08-30T09:09:20.690511Z","iopub.status.idle":"2024-08-30T09:09:20.696515Z","shell.execute_reply.started":"2024-08-30T09:09:20.690456Z","shell.execute_reply":"2024-08-30T09:09:20.695598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Utils","metadata":{}},{"cell_type":"code","source":"def copy_images(source_dir, destination_dir):\n    \"\"\"Copy images from source to destination directory.\"\"\"\n    os.makedirs(destination_dir, exist_ok=True)\n    for filename in os.listdir(source_dir):\n        if filename.endswith(('.jpg', '.png')):\n            shutil.copy2(os.path.join(source_dir, filename), os.path.join(destination_dir, filename))\n    print(f\"All images from {source_dir} have been copied to {destination_dir}.\")\n\ndef convert_annotation_to_yolo_format(xml_file, img_width, img_height):\n    \"\"\"Convert XML annotations to YOLO format.\"\"\"\n    yolo_annotations = []\n    tree = ET.parse(xml_file)\n    root = tree.getroot()\n\n    for obj in root.findall('object'):\n        cls_name = obj.find('name').text\n        if cls_name not in classes:\n            continue  # Skip if class is not in our predefined classes\n\n        cls_id = classes[cls_name]\n\n        xmlbox = obj.find('bndbox')\n        xmin = int(xmlbox.find('xmin').text)\n        ymin = int(xmlbox.find('ymin').text)\n        xmax = int(xmlbox.find('xmax').text)\n        ymax = int(xmlbox.find('ymax').text)\n\n        x_center = ((xmin + xmax) / 2.0) / img_width\n        y_center = ((ymin + ymax) / 2.0) / img_height\n        width = (xmax - xmin) / float(img_width)\n        height = (ymax - ymin) / float(img_height)\n\n        yolo_annotations.append((cls_id, x_center, y_center, width, height))\n    \n    return yolo_annotations\n\ndef save_yolo_annotations(xml_file, txt_file, img_width, img_height):\n    \"\"\"Convert XML annotations to YOLO format and save them to a text file.\"\"\"\n    yolo_annotations = convert_annotation_to_yolo_format(xml_file, img_width, img_height)\n    with open(txt_file, 'w') as f:\n        for ann in yolo_annotations:\n            cls_id, x_center, y_center, width, height = ann\n            f.write(f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n\ndef process_annotations(subset):\n    \"\"\"Process annotations and images for a given subset (train/val).\"\"\"\n    images_path = os.path.join(base_dataset_path, subset, 'images')\n    annotations_path = os.path.join(base_dataset_path, subset, 'annotations')\n    yolo_labels_path = os.path.join(output_base_path, subset, 'labels')\n\n    os.makedirs(yolo_labels_path, exist_ok=True)\n\n    for annotation_file in os.listdir(annotations_path):\n        if annotation_file.endswith('.xml'):\n            xml_file = os.path.join(annotations_path, annotation_file)\n            image_file = os.path.join(images_path, annotation_file.replace('.xml', '.jpg'))\n            txt_file = os.path.join(yolo_labels_path, annotation_file.replace('.xml', '.txt'))\n\n            if not os.path.exists(image_file):\n                print(f\"Image file not found for annotation: {annotation_file}\")\n                continue\n\n            img = cv2.imread(image_file)\n            img_height, img_width, _ = img.shape\n            save_yolo_annotations(xml_file, txt_file, img_width, img_height)\n\n    print(f\"All annotations for {subset} have been converted to YOLO format successfully.\")\n\ndef remove_empty_labels(labels_path):\n    \"\"\"Remove empty or corrupted label files.\"\"\"\n    empty_labels = [f for f in os.listdir(labels_path) if os.path.getsize(os.path.join(labels_path, f)) == 0]\n    for label_file in empty_labels:\n        os.remove(os.path.join(labels_path, label_file))\n        print(f\"Removed corrupted label file: {label_file}\")\n\ndef update_labels(labels_path):\n    \"\"\"Update label files to exclude specified classes.\"\"\"\n    for label_file in os.listdir(labels_path):\n        if label_file.endswith('.txt'):\n            file_path = os.path.join(labels_path, label_file)\n            with open(file_path, 'r') as f:\n                lines = f.readlines()\n            \n            updated_lines = [line for line in lines if int(line.split()[0]) not in indices_to_ignore]\n            \n            with open(file_path, 'w') as f:\n                f.writelines(updated_lines)\n\ndef create_data_yaml():\n    \"\"\"Create the data.yaml file for YOLO training.\"\"\"\n    data_yaml_content = f\"\"\"\ntrain: {os.path.join(output_base_path, 'train/images')}\nval: {os.path.join(output_base_path, 'val/images')}\n\nnc: {len(classes)}  # Number of classes\nnames: {list(classes.keys())}\n\"\"\"\n    with open('/kaggle/working/data.yaml', 'w') as file:\n        file.write(data_yaml_content)\n    print(\"data.yaml file created successfully!\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-30T09:09:20.697886Z","iopub.execute_input":"2024-08-30T09:09:20.698163Z","iopub.status.idle":"2024-08-30T09:09:20.719956Z","shell.execute_reply.started":"2024-08-30T09:09:20.698133Z","shell.execute_reply":"2024-08-30T09:09:20.719037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Copy images and process annotations for each subset\nfor subset in subsets:\n    copy_images(os.path.join(base_dataset_path, subset, 'images'), os.path.join(output_base_path, subset, 'images'))\n    process_annotations(subset)\n    remove_empty_labels(os.path.join(output_base_path, subset, 'labels'))\n    update_labels(os.path.join(output_base_path, subset, 'labels'))","metadata":{"execution":{"iopub.status.busy":"2024-08-30T09:09:20.721025Z","iopub.execute_input":"2024-08-30T09:09:20.721333Z","iopub.status.idle":"2024-08-30T09:10:26.639006Z","shell.execute_reply.started":"2024-08-30T09:09:20.721300Z","shell.execute_reply":"2024-08-30T09:10:26.637875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### YAML","metadata":{}},{"cell_type":"code","source":"create_data_yaml()","metadata":{"execution":{"iopub.status.busy":"2024-08-30T09:10:26.640318Z","iopub.execute_input":"2024-08-30T09:10:26.640859Z","iopub.status.idle":"2024-08-30T09:10:26.646381Z","shell.execute_reply.started":"2024-08-30T09:10:26.640823Z","shell.execute_reply":"2024-08-30T09:10:26.645302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize Weights & Biases\nwandb.init(project='IDD', name='yolov8n-basemodel-1')","metadata":{"execution":{"iopub.status.busy":"2024-08-30T09:46:54.738067Z","iopub.execute_input":"2024-08-30T09:46:54.738446Z","iopub.status.idle":"2024-08-30T09:47:12.018009Z","shell.execute_reply.started":"2024-08-30T09:46:54.738413Z","shell.execute_reply":"2024-08-30T09:47:12.017049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training","metadata":{}},{"cell_type":"code","source":"def train_yolo_model():\n    \"\"\"Train the YOLO model with customized hyperparameters.\"\"\"\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    print(f\"Using device: {device}\")\n\n    model = YOLO('yolov8n.pt')  # Load the pre-trained YOLOv8n model\n\n    # Set your custom hyperparameters\n    results = model.train(\n        data='/kaggle/working/data.yaml', \n        epochs=100,  \n        batch=16,  \n        imgsz=640,  \n        lr0=0.001,  \n        optimizer='Adam',  \n        momentum=0.937,\n        weight_decay=0.0005,\n        name='yolov8n_idd_basemodel-1',  \n        device=device,  \n        project='IDD', \n    )\n    \n    # Save the trained model\n    model.save('/kaggle/working/yolov8n_idd_basemodel-1.pt')\n\n    # Validate the model and print key metrics\n    val_results = model.val()\n    print(f\"Validation mAP50: {val_results.box.map50:.4f}, Precision: {val_results.box.mp:.4f}, Recall: {val_results.box.mr:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-30T09:47:26.204413Z","iopub.execute_input":"2024-08-30T09:47:26.204852Z","iopub.status.idle":"2024-08-30T09:47:26.213154Z","shell.execute_reply.started":"2024-08-30T09:47:26.204811Z","shell.execute_reply":"2024-08-30T09:47:26.211917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\ntrain_yolo_model()","metadata":{"execution":{"iopub.status.busy":"2024-08-30T09:47:28.437411Z","iopub.execute_input":"2024-08-30T09:47:28.438186Z","iopub.status.idle":"2024-08-30T10:25:45.053028Z","shell.execute_reply.started":"2024-08-30T09:47:28.438146Z","shell.execute_reply":"2024-08-30T10:25:45.051910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the saved YOLO model from the specified path\nmodel = YOLO('/kaggle/working/yolov8n_idd_basemodel.pt')\nprint(\"Model loaded successfully.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-30T09:44:14.288824Z","iopub.execute_input":"2024-08-30T09:44:14.289217Z","iopub.status.idle":"2024-08-30T09:44:14.352273Z","shell.execute_reply.started":"2024-08-30T09:44:14.289181Z","shell.execute_reply":"2024-08-30T09:44:14.351095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Testing","metadata":{}},{"cell_type":"code","source":"# Test on a single image\ntest_image_path = '/kaggle/input/idd-dataset/IDD_Detection_Organized/val/images/0000285.jpg'\n\n# Run inference on the test image using the loaded model\nresults = model(test_image_path)\n\n# Function to display image with bounding boxes\ndef display_results(image_path, results):\n    \"\"\"Display image with YOLO detection results.\"\"\"\n    image = cv2.imread(image_path)\n    img_height, img_width, _ = image.shape\n\n    # Loop through each detection in results\n    for result in results[0].boxes:\n        cls_id = int(result.cls.item())  # Convert class ID tensor to int\n        conf = result.conf.item()  # Convert confidence tensor to float\n        xmin, ymin, xmax, ymax = map(int, result.xyxy[0].tolist())  # Convert bounding box coordinates to integers\n\n        # Draw the bounding box\n        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n        # Put class name and confidence on the image\n        label = f\"{list(classes.keys())[cls_id]}: {conf:.2f}\"\n        cv2.putText(image, label, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Convert BGR image (OpenCV default) to RGB for matplotlib display\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    \n    plt.figure(figsize=(10, 6))\n    plt.imshow(image_rgb)\n    plt.axis('off')\n    plt.show()\n\n# Display the results\ndisplay_results(test_image_path, results)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T09:42:27.464058Z","iopub.execute_input":"2024-08-30T09:42:27.464851Z","iopub.status.idle":"2024-08-30T09:42:28.016232Z","shell.execute_reply.started":"2024-08-30T09:42:27.464807Z","shell.execute_reply":"2024-08-30T09:42:28.015191Z"},"trusted":true},"execution_count":null,"outputs":[]}]}